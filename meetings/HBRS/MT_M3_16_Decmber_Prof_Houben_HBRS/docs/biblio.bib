@article{001,
  title={A review of deep learning-based semantic segmentation for point cloud},
  author={Zhang, Jiaying and Zhao, Xiaoli and Chen, Zheng and Lu, Zhejun},
  journal={IEEE Access},
  volume={7},
  pages={179118--179133},
  year={2019},
  publisher={IEEE}
}
@INPROCEEDINGS{002,
  author={Lowphansirikul, Chakri and Kim, Kvoung-Sook and Vinayaraj, Poliyapram and Tuarob, Suppawong},
  booktitle={2019 11th International Conference on Knowledge and Smart Technology (KST)}, 
  title={3D Semantic Segmentation of Large-Scale Point-Clouds in Urban Areas Using Deep Learning}, 
  year={2019},
  volume={},
  number={},
  pages={238-243},
  doi={10.1109/KST.2019.8687813}}

@InProceedings{003,
author = {Su, Hang and Jampani, Varun and Sun, Deqing and Maji, Subhransu and Kalogerakis, Evangelos and Yang, Ming-Hsuan and Kautz, Jan},
title = {SPLATNet: Sparse Lattice Networks for Point Cloud Processing},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@article{004,
  title={Latticenet: Fast point cloud segmentation using permutohedral lattices},
  author={Rosu, Radu Alexandru and Sch{\"u}tt, Peer and Quenzel, Jan and Behnke, Sven},
  journal={arXiv preprint arXiv:1912.05905},
  year={2019}
}

@INPROCEEDINGS{sseg,
  author={Wu, Bichen and Wan, Alvin and Yue, Xiangyu and Keutzer, Kurt},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={SqueezeSeg: Convolutional Neural Nets with Recurrent CRF for Real-Time Road-Object Segmentation from 3D LiDAR Point Cloud}, 
  year={2018},
  volume={},
  number={},
  pages={1887-1893},
  doi={10.1109/ICRA.2018.8462926}}
  
 @INPROCEEDINGS{ssegv2,
  author={Wu, Bichen and Zhou, Xuanyu and Zhao, Sicheng and Yue, Xiangyu and Keutzer, Kurt},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)}, 
  title={SqueezeSegV2: Improved Model Structure and Unsupervised Domain Adaptation for Road-Object Segmentation from a LiDAR Point Cloud}, 
  year={2019},
  volume={},
  number={},
  pages={4376-4382},
  doi={10.1109/ICRA.2019.8793495}}
 
 @INPROCEEDINGS{salsanet,
  author={Aksoy, Eren Erdal and Baci, Saimir and Cavdar, Selcuk},
  booktitle={2020 IEEE Intelligent Vehicles Symposium (IV)}, 
  title={SalsaNet: Fast Road and Vehicle Segmentation in LiDAR Point Clouds for Autonomous Driving}, 
  year={2020},
  volume={},
  number={},
  pages={926-932},
  doi={10.1109/IV47402.2020.9304694}}
 
 
 @InProceedings{salsanext,
author="Cortinhal, Tiago
and Tzelepis, George
and Erdal Aksoy, Eren",
editor="Bebis, George
and Yin, Zhaozheng
and Kim, Edward
and Bender, Jan
and Subr, Kartic
and Kwon, Bum Chul
and Zhao, Jian
and Kalkofen, Denis
and Baciu, George",
title="SalsaNext: Fast, Uncertainty-Aware Semantic Segmentation of LiDAR Point Clouds",
booktitle="Advances in Visual Computing",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="207--222",
abstract="In this paper, we introduce SalsaNext for the uncertainty-aware semantic segmentation of a full 3D LiDAR point cloud in real-time. SalsaNext is the next version of SalsaNet [1] which has an encoder-decoder architecture where the encoder unit has a set of ResNet blocks and the decoder part combines upsampled features from the residual blocks. In contrast to SalsaNet, we introduce a new context module, replace the ResNet encoder blocks with a new residual dilated convolution stack with gradually increasing receptive fields and add the pixel-shuffle layer in the decoder. Additionally, we switch from stride convolution to average pooling and also apply central dropout treatment. To directly optimize the Jaccard index, we further combine the weighted cross entropy loss with Lov{\'a}sz-Softmax loss [4]. We finally inject a Bayesian treatment to compute the epistemic and aleatoric uncertainties for each point in the cloud. We provide a thorough quantitative evaluation on the Semantic-KITTI dataset [3], which demonstrates that the proposed SalsaNext outperforms other published semantic segmentation networks and achieves {\$}{\$}3.6{\backslash}{\%}{\$}{\$}3.6{\%}more accuracy over the previous state-of-the-art method. We also release our source code (https://github.com/TiagoCortinhal/SalsaNext).",
isbn="978-3-030-64559-5"
}

@ARTICLE{3dmininet,
  author={Alonso, Iñigo and Riazuelo, Luis and Montesano, Luis and Murillo, Ana C.},
  journal={IEEE Robotics and Automation Letters}, 
  title={3D-MiniNet: Learning a 2D Representation From Point Clouds for Fast and Efficient 3D LIDAR Semantic Segmentation}, 
  year={2020},
  volume={5},
  number={4},
  pages={5432-5439},
  doi={10.1109/LRA.2020.3007440}}
  
  @InProceedings{polarnet,
author = {Zhang, Yang and Zhou, Zixiang and David, Philip and Yue, Xiangyu and Xi, Zerong and Gong, Boqing and Foroosh, Hassan},
title = {PolarNet: An Improved Grid Representation for Online LiDAR Point Clouds Semantic Segmentation},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@InProceedings{Randlanet,
author = {Hu, Qingyong and Yang, Bo and Xie, Linhai and Rosa, Stefano and Guo, Yulan and Wang, Zhihua and Trigoni, Niki and Markham, Andrew},
title = {RandLA-Net: Efficient Semantic Segmentation of Large-Scale Point Clouds},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@INPROCEEDINGS{Rangenet,
  author={Milioto, Andres and Vizzo, Ignacio and Behley, Jens and Stachniss, Cyrill},
  booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={RangeNet ++: Fast and Accurate LiDAR Semantic Segmentation}, 
  year={2019},
  volume={},
  number={},
  pages={4213-4220},
  doi={10.1109/IROS40897.2019.8967762}}
  
@article{kprnet,
  title={Kprnet: Improving projection-based lidar semantic segmentation},
  author={Kochanov, Deyvid and Nejadasl, Fatemeh Karimi and Booij, Olaf},
  journal={arXiv preprint arXiv:2007.12668},
  year={2020}
}