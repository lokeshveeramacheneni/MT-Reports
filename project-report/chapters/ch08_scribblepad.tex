%!TEX root = ../report.tex

\begin{document}
\chapter{Notes/Remarks}
\section{Related work - Models}

In this section, we will discuss about the methods available for 3D semantic segmentation.
The discussion include a breif peek into traditional 3D semantic segmentation methods and study of deep learning based 3D point cloud segmentation.

Traditional methods involve a complex features extraction and pass these features to a classficiation algorithm such as Support Vector Machines or Random Forests to classify each point the point cloud.
Various authors developed variety of methods to extract the features from the input point cloud.
Some of these methods include segmentation from edge information \cite{bhanu1986range}, construction of complex graph pyramids \cite{koster}.
3D Hough transforms as in \cite{vosselman20013d} and application of RANSAC \cite{schnabel2007efficient} and \cite{tarsha2007hough}.
These traditional methods are now outdated as DNNs proved to better at feature extraction.

\subsection{Deep learning based 3D semantic segmentation}


\begin{table}[h!]
    \centering
    \begin{tabular}{|p{0.15\linewidth} | p{0.6\linewidth}| p{0.06\linewidth} |p{0.08\linewidth}|}
        \hline
        Method & Summary & Type & \#Params \\
        \hline 
        PointNet\cite{Qi_2017_CVPR_pointnet} &  & Point & 3M \\
        \hline
        PointNet++\cite{qi2017pointnet++} & & Point & 6M \\
        \hline
        TangentConv\cite{Tatarchenko_2018_CVPR_tangconv} & & Point & 0.4M\\
        \hline
        SPLATNet\cite{Su_2018_CVPR_splatnet} & & Point & 0.8M \\
        \hline
        Squeezeseg\cite{Sequeseseg_2018} & & Project & 1M \\
        \hline
        SPGraph\cite{SPGraph} & & Point & 0.25M\\
        \hline
        LatticeNet\cite{rosu2019latticenet} & & Point & - \\
        \hline
        SqueezesegV2\cite{SqueezeSegv2} & & Project & 1M \\
        \hline
        RangeNet-21\cite{Milioto2019} & 
        Spherical projection based model with encoder-decoder style architecture with encoder being DarkNet21.
        Introduced a better evaluation metric called borderIoU for occlusions.
        & Project & 25M \\
        \hline
        RangeNet-53\cite{Milioto2019}  & 
        Architecturally similar to RangeNet-21, the only change is encoder which is DarkNet53.
        No postprocessing is applied for occlusions or nonprojected points.
        & Project & 50M \\
        \hline
        RangeNet-53++\cite{Milioto2019} &
        RangeNet-53++ architecture is same as RangeNet-53 but a post processing method of kNN is applied on output to label the occluded points or nonprojected points after reprojection from segmented 2D Spherical image to 3D points.
        
        & Project & 50M \\
        \hline
        SqueezesegV3\cite{xu2020squeezesegv3} & & Project & 0.92M \\
        \hline
        RandLA-Net\cite{Hu_2020_CVPR_Randla} & 
        Random points from input point cloud are sampled and fed into local feature aggregation (LFA) module for feature extraction.
        These fetures are weighted and selected based on the attention score. 
        Encoder-decoder style architecture with stacks of LFA as encoder and decoder is transponse convolutions for upsampling with MLP followed by fully connected layers for segmentation.
        & Point & 0.95M \\
        \hline 
        3DMiniNet\cite{3Dmininet} & & Project & 4M \\
        \hline
        SalsaNet\cite{salsanet2020} & Encoder-decoder style architecture with Bird-Eye-View projection as input and encoder consisting of ResNet blocks and decoder with transpose convolutions.
        Unlabelled points in LiDAR are auto labelled from corresponding images. Claims SalsaNet is projection agnostic.
        & Project & 6.6M \\
        \hline
        SalsaNext\cite{SalsaNext_2020} & & Project & 6.7M \\
        \hline
        PolarNet\cite{polarnet} & & Project & 14M \\
        \hline
        KPRNet\cite{kochanov2020kprnet} & & Project & 243M \\
        \hline
        SPVNAS\cite{spvnas} & & Point & 2.6M \\
        \hline
        Cylinder3D\cite{zhu2020cylindrical} & & Project & - \\
        \hline
        (AF)2-S3Net\cite{af2s3net} & & Point & - \\
        \hline

    \end{tabular}
\end{table}
\begin{figure}[h!]
    \centering
    \includestandalone[width=0.6\linewidth]{images/models_plot}
    \caption{Comparison of 3D semantic segmentation methods performance on SemanticKITTI dataset against the number of parameters. 
             Blue points represent point based methods and red represented projection based methods.}
\end{figure}


\newpage

\end{document}
